{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T14:48:36.749393Z",
     "start_time": "2025-10-02T14:48:36.489710Z"
    }
   },
   "source": [
    "# Super simple Linear Regression on your CSV\n",
    "# No pipelines, no complex preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 1) Load the data\n",
    "csv_path = \"ensurance.csv\"  # <- make sure the file is in the same folder\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Split into features (X) and target (y)\n",
    "y = df[\"charges\"]\n",
    "X = df.drop(columns=[\"charges\"])\n",
    "\n",
    "# 3) Turn text columns into numbers (one-hot encoding) the easy way\n",
    "#    drop_first=True avoids duplicate columns for categories\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4) Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5) Make the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 6) Train (fit) the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7) Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"hada :{model.intercept_}{model.coef_}\") and print(model.coef_)\n",
    "# 8) Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Linear Regression (basic) results on test set\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "# 9) (Optional) Show a few predictions vs real values\n",
    "preview = pd.DataFrame({\n",
    "    \"Actual\": y_test.values[:10],\n",
    "    \"Predicted\": y_pred[:10]\n",
    "})\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "print(preview)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hada :-11931.219050326692[ 2.56975706e+02  3.37092552e+02  4.25278784e+02 -1.85916916e+01\n",
      "  2.36511289e+04 -3.70677326e+02 -6.57864297e+02 -8.09799354e+02]\n",
      "Linear Regression (basic) results on test set\n",
      "RMSE: 5796.28\n",
      "MAE:  4181.19\n",
      "R²:   0.7836\n",
      "\n",
      "Sample predictions (first 10):\n",
      "        Actual     Predicted\n",
      "0   9095.06825   8969.550274\n",
      "1   5272.17580   7068.747443\n",
      "2  29330.98315  36858.410912\n",
      "3   9301.89355   9454.678501\n",
      "4  33750.29180  26973.173457\n",
      "5   4536.25900  10864.113164\n",
      "6   2117.33885    170.280841\n",
      "7  14210.53595  16903.450287\n",
      "8   3732.62510   1092.430936\n",
      "9  10264.44210  11218.343184\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:55:16.761631Z",
     "start_time": "2025-10-02T14:55:16.206522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare LinearRegression, RandomForestRegressor, XGBRegressor, and SVR\n",
    "# Simple style: pandas.get_dummies + train_test_split + fit/predict + metrics\n",
    "# Note: SVR needs scaling; we'll scale only for SVR to keep it simple.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Try XGBoost if installed; skip if not\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "# 1) Load the data\n",
    "csv_path = \"ensurance.csv\"  # <- update if your file has a different name/path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Features/target\n",
    "y = df[\"charges\"]\n",
    "X = df.drop(columns=[\"charges\"])\n",
    "\n",
    "# 3) Easy one-hot encoding for categorical columns\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4) Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5) Prepare models (default params)\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=42),\n",
    "    \"SVR\": SVR(),  # default RBF kernel; needs scaling\n",
    "}\n",
    "if HAS_XGB:\n",
    "    models[\"XGBRegressor\"] = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "# 6) Helper to compute metrics\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# 7) Baseline (always predict the mean) to compare against\n",
    "baseline = y_train.mean()\n",
    "y_pred_base = np.full_like(y_test, baseline, dtype=float)\n",
    "rmse_b = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
    "print(f\"Baseline (predict mean) RMSE: {rmse_b:.2f}\\n\")\n",
    "\n",
    "# 8) Train, predict, evaluate each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    if name == \"SVR\":\n",
    "        # Scale features ONLY for SVR (everything is numeric after get_dummies)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_use = scaler.fit_transform(X_train)\n",
    "        X_test_use = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "\n",
    "    # Fit\n",
    "    model.fit(X_train_use, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_use)\n",
    "\n",
    "    # Metrics\n",
    "    rmse, mae, r2 = eval_metrics(y_test, y_pred)\n",
    "    results.append({\"Model\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n",
    "\n",
    "    print(f\"{name} results:\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "\n",
    "    # Optional: show a few predictions for the first model only to keep output short\n",
    "    if name == \"LinearRegression\":\n",
    "        preview = pd.DataFrame({\"Actual\": y_test.values[:5], \"Predicted\": y_pred[:5]})\n",
    "        print(\"  Sample predictions:\\n\", preview, \"\\n\")\n",
    "\n",
    "# 9) Summary table sorted by RMSE (lower is better)\n",
    "results_df = pd.DataFrame(results).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "print(\"\\nSummary (sorted by RMSE):\")\n",
    "print(results_df)"
   ],
   "id": "25d9b345d713f7ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (predict mean) RMSE: 12465.61\n",
      "\n",
      "LinearRegression results:\n",
      "  RMSE: 5796.28\n",
      "  MAE:  4181.19\n",
      "  R²:   0.7836\n",
      "  Sample predictions:\n",
      "         Actual     Predicted\n",
      "0   9095.06825   8969.550274\n",
      "1   5272.17580   7068.747443\n",
      "2  29330.98315  36858.410912\n",
      "3   9301.89355   9454.678501\n",
      "4  33750.29180  26973.173457 \n",
      "\n",
      "RandomForestRegressor results:\n",
      "  RMSE: 4576.30\n",
      "  MAE:  2550.08\n",
      "  R²:   0.8651\n",
      "SVR results:\n",
      "  RMSE: 12889.10\n",
      "  MAE:  8612.41\n",
      "  R²:   -0.0701\n",
      "\n",
      "Summary (sorted by RMSE):\n",
      "                   Model          RMSE          MAE        R2\n",
      "0  RandomForestRegressor   4576.299916  2550.078471  0.865103\n",
      "1       LinearRegression   5796.284659  4181.194474  0.783593\n",
      "2                    SVR  12889.096315  8612.408423 -0.070082\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:48:37.561238Z",
     "start_time": "2025-10-02T14:48:37.443854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# -----------------------\n",
    "# Helper: IQR bounds\n",
    "# -----------------------\n",
    "def iqr_bounds(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return lower, upper\n",
    "\n",
    "# 1) Load data\n",
    "csv_path = \"ensurance.csv\"  # change if different\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Split features/target\n",
    "y = df[\"charges\"]\n",
    "X = df.drop(columns=[\"charges\"])\n",
    "\n",
    "# 3) One-hot encode categoricals (simple)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4) Train/test split (train only is used to compute IQR bounds)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 5) IQR handling\n",
    "# -----------------------\n",
    "\n",
    "# 5a) Target outliers: CAP y_train using IQR on y_train only\n",
    "y_lo, y_hi = iqr_bounds(y_train)\n",
    "# For medical charges, the lower fence can be very low; we usually cap top-end only\n",
    "y_train_capped = y_train.clip(lower=y_lo, upper=y_hi)\n",
    "\n",
    "# 5b) Feature outliers: clip numeric columns using bounds learned from X_train\n",
    "numeric_cols = [c for c in [\"age\", \"bmi\", \"children\"] if c in X_train.columns]\n",
    "for col in numeric_cols:\n",
    "    lo, hi = iqr_bounds(X_train[col])\n",
    "    # clip both train and test using TRAIN bounds (no leakage)\n",
    "    X_train[col] = X_train[col].clip(lower=lo, upper=hi)\n",
    "    X_test[col]  = X_test[col].clip(lower=lo, upper=hi)\n",
    "\n",
    "# -----------------------\n",
    "# 6) Scale (SVR needs scaled inputs)\n",
    "# -----------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# 7) Train SVR (simple, reasonable defaults)\n",
    "# -----------------------\n",
    "svr = SVR(C=10, epsilon=0.2, gamma=\"scale\")\n",
    "svr.fit(X_train_s, y_train_capped)\n",
    "\n",
    "# 8) Predict on test\n",
    "y_pred = svr.predict(X_test_s)\n",
    "\n",
    "# 9) Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"SVR with IQR capping (target) + IQR clipping (features) + scaling\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "# Optional: Show first 5 predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(pd.DataFrame({\"Actual\": y_test.values[:5], \"Predicted\": y_pred[:5]}))"
   ],
   "id": "d5b2d016a9df9000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with IQR capping (target) + IQR clipping (features) + scaling\n",
      "RMSE: 12845.02\n",
      "MAE:  8190.24\n",
      "R²:   -0.0628\n",
      "\n",
      "Sample predictions:\n",
      "        Actual     Predicted\n",
      "0   9095.06825   9312.603710\n",
      "1   5272.17580   8813.004922\n",
      "2  29330.98315  10227.751613\n",
      "3   9301.89355   9373.441122\n",
      "4  33750.29180   8134.539415\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
